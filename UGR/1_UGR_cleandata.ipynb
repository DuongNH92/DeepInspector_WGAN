{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcfe9140",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read data\n",
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "dt0 = dd.read_csv(\"../dataset/UGR/big_dataset/0_bacground.csv\", header=None)\n",
    "dt0.columns=['timestamp','duration','source_ip',\n",
    "            'dest_ip','source_port','dest_port','protocol',\n",
    "            'flag','fwd','stos','pkt','byt','Label']\n",
    "dt1 = dd.read_csv(\"../dataset/UGR/big_dataset/1_blacklist_flows_cut.csv\", header=None)\n",
    "dt1.columns=['timestamp','duration','source_ip',\n",
    "            'dest_ip','source_port','dest_port','protocol',\n",
    "            'flag','fwd','stos','pkt','byt','Label']\n",
    "dt2 = dd.read_csv(\"../dataset/UGR/big_dataset/2_botnet_flows_cut.csv\", header=None)\n",
    "dt2.columns=['timestamp','duration','source_ip',\n",
    "            'dest_ip','source_port','dest_port','protocol',\n",
    "            'flag','fwd','stos','pkt','byt','Label']\n",
    "dt3 = dd.read_csv(\"../dataset/UGR/big_dataset/3_dos_flows_cut.csv\", header=None)\n",
    "dt3.columns=['timestamp','duration','source_ip',\n",
    "            'dest_ip','source_port','dest_port','protocol',\n",
    "            'flag','fwd','stos','pkt','byt','Label']\n",
    "dt4 = dd.read_csv(\"../dataset/UGR/big_dataset/4_scan11_flows_cut.csv\", header=None)\n",
    "dt4.columns=['timestamp','duration','source_ip',\n",
    "            'dest_ip','source_port','dest_port','protocol',\n",
    "            'flag','fwd','stos','pkt','byt','Label']\n",
    "dt5 = dd.read_csv(\"../dataset/UGR/big_dataset/5_scan44_flows_cut.csv\", header=None)\n",
    "dt5.columns=['timestamp','duration','source_ip',\n",
    "            'dest_ip','source_port','dest_port','protocol',\n",
    "            'flag','fwd','stos','pkt','byt','Label']\n",
    "dt6 = dd.read_csv(\"../dataset/UGR/big_dataset/6_spam_flows_cut.csv\", header=None)\n",
    "dt6.columns=['timestamp','duration','source_ip',\n",
    "            'dest_ip','source_port','dest_port','protocol',\n",
    "            'flag','fwd','stos','pkt','byt','Label']\n",
    "dt7 = dd.read_csv(\"../dataset/UGR/big_dataset/7_sshscan_flows_cut.csv\", header=None)\n",
    "dt7.columns=['timestamp','duration','source_ip',\n",
    "            'dest_ip','source_port','dest_port','protocol',\n",
    "            'flag','fwd','stos','pkt','byt','Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8837dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = dt0[dt0['Label']==\"background\"].compute().sample(n=20000, replace=False, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39a75df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = dt1.compute().sample(n=20000, replace=False, random_state=1) #blacklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d494bfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a2 = dt2.compute().sample(n=2000, replace=False, random_state=1) #botnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b08b175",
   "metadata": {},
   "outputs": [],
   "source": [
    "a3 = dt3.compute().sample(n=4500, replace=False, random_state=1) #dos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cd1fc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "a4 = dt4.compute().sample(n=20000, replace=False, random_state=1) #scan11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b98b69cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "a5 = dt5.compute().sample(n=20000, replace=False, random_state=1) #scan44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c808f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a6 = dt6.compute().sample(n=400, replace=False, random_state=1) #spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51b02d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "a7 = dt7.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17bea48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "scan11             20000\n",
      "background         20000\n",
      "blacklist          20000\n",
      "scan44             20000\n",
      "dos                 4500\n",
      "nerisbotnet         2000\n",
      "anomaly-spam         400\n",
      "anomaly-sshscan      109\n",
      "Name: Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Merge data\n",
    "data1 = pd.concat([normal,a1,a2,a3,a4,a5,a6,a7],ignore_index = True,axis=0)\n",
    "data_train = shuffle(data1).reset_index(drop=True)\n",
    "print(\"-----------------------------------\")\n",
    "print(data_train['Label'].value_counts())\n",
    "data_train.to_csv(\"../dataset/UGR/original_0.csv\", index=False, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e7d44fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting convert data...\n",
      "Converting...\n",
      "Completed!\n"
     ]
    }
   ],
   "source": [
    "# Convert data\n",
    "import argparse\n",
    "import platform, logging, os\n",
    "import re\n",
    "import csv\n",
    "import ipaddress\n",
    "\n",
    "REG_EXPR = '^2016-07-\\d{2} \\d{2}:\\d{2}:\\d{2},\\d+\\.\\d+,\\d+\\.\\d+\\.\\d+\\.\\d+,\\d+\\.\\d+\\.\\d+\\.\\d+,\\d+,\\d+,[A-Z]+,[A-Z\\.]{6},\\d+,\\d+,\\d+,\\d+,.+[sd]$'\n",
    "\n",
    "def convert(row):\n",
    "    outrow = []\n",
    "    d, t = row[0].split(' ')\n",
    "                # split the date into 3 columns\n",
    "    for val in d.split('-'):\n",
    "        outrow.append(val)\n",
    "        \n",
    "                # split the time into 3 columns\n",
    "    for val in t.split(':'): \n",
    "        outrow.append(val)\n",
    "    outrow.append(row[1])\n",
    "\n",
    "    # convert IP adresses to integer value \n",
    "    outrow.append(int(ipaddress.ip_address(row[2]))) \n",
    "    outrow.append(int(ipaddress.ip_address(row[3]))) \n",
    "    outrow.append(row[4]) \n",
    "    outrow.append(row[5])\n",
    "    \n",
    "    # convert: TCP -> 1 ; UDP -> 2 ; ICMP -> 3; GRE -> 4; IPIP -> 5; & rest\n",
    "    if row[6] == 'TCP': \n",
    "        outrow.append(1)\n",
    "    elif row[6] == 'UDP': \n",
    "        outrow.append(2)\n",
    "    elif row[6] == 'ICMP':\n",
    "        outrow.append(3)\n",
    "    elif row[6] == 'GRE':\n",
    "        outrow.append(4)\n",
    "    elif row[6] == 'IPIP':\n",
    "        outrow.append(5)\n",
    "    else:\n",
    "        outrow.append(6)\n",
    "\n",
    "    # convert Flags to ASCII value & split it into different columns\n",
    "    for ch in row[7]:\n",
    "        outrow.append(ord(ch))\n",
    "    outrow.append (row[8])\n",
    "    outrow.append (row[9])\n",
    "    outrow.append (row[10])\n",
    "    outrow.append (row[11])\n",
    "    outrow.append (row[12])\n",
    "    return outrow\n",
    "    \n",
    "def main (data_in, data_out):\n",
    "    \n",
    "    if data_out == \"\":\n",
    "        data_out = \"../dataset/UGR/original_1.csv\"\n",
    "    if data_in == \"\":\n",
    "        data_in = \"../dataset/UGR/original_0.csv\"\n",
    "    with open(data_in) as in_dt:\n",
    "        with open(data_out, 'w', newline ='') as out_dt:\n",
    "            print(\"Starting convert data...\")\n",
    "            writer = csv.writer(out_dt)\n",
    "            r = re.compile (REG_EXPR)\n",
    "\n",
    "            read = csv.reader(in_dt)\n",
    "            next(read)\n",
    "            \n",
    "            print(\"Converting...\")\n",
    "            for row in read:\n",
    "                if (convert(row) == 0):\n",
    "                    pass\n",
    "                else:\n",
    "                    writer.writerow(convert(row))\n",
    "            print(\"Completed!\")\n",
    "if __name__ == \"__main__\":  \n",
    "    main(\"\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b5e2360",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "dd = pd.read_csv(\"../dataset/UGR/original_1.csv\", header=None)\n",
    "dd.columns=['year','month','day','hour','minute','second','duration',\n",
    "            'source_ip','dest_ip','source_port','dest_port','protocol',\n",
    "            'flag1','flag2','flag3','flag4','flag5','flag6','fwd','stos','pkt','byt', 'Label']\n",
    "dd = dd.drop(['year','month','day'], axis = 1)\n",
    "\n",
    "dataset = dd.values\n",
    "X = dataset[:,0:19]\n",
    "y = dataset[:,19]\n",
    "\n",
    "# convert the scaled array to dataframe \n",
    "min_max_scaler = MinMaxScaler()\n",
    "X_scale = min_max_scaler.fit_transform(X)\n",
    "\n",
    "data_x = pd.DataFrame(X_scale, columns = ['hour','minute','second','duration','source_ip','dest_ip','source_port','dest_port','protocol',\n",
    "                'flag1','flag2','flag3','flag4','flag5','flag6','fwd','stos','pkt','byt'])\n",
    "data_y = pd.DataFrame(y, columns = ['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da2bbaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat([data_x, data_y],ignore_index = True,axis=1)\n",
    "dataset.columns = ['hour','minute','second','duration','source_ip','dest_ip','source_port','dest_port','protocol',\n",
    "                'flag1','flag2','flag3','flag4','flag5','flag6','fwd','stos','pkt','byt','Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "001e0176",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdataset\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts())\n\u001b[1;32m      2\u001b[0m dataset\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../dataset/UGR/original.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, header \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "print(dataset['Label'].value_counts())\n",
    "dataset.to_csv(\"../dataset/UGR/original.csv\", index=False, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2fae6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
